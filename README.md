# tweets-analysis-NLP and APi deployment
Use case of a client (@TheBridge_Tech) who wants to develop a social media monitoring to measure the impact of the brand and develop commercial actions.
(API, NLP, MLOps)

### Welcome!
 
Thank you for taking an interest in my proyect ğŸ™‚
 
Here I've worked with:

Python ğŸ Â· Sqlite3 ğŸ” Â· Pandas ğŸ¼ Â· SciKitLearn ğŸ¥¼ Â· NLTK ğŸ“– Â· Regex ğŸ’¬ Â· WordCloud ğŸŒ¥ Â· TextBlob ğŸ† Â· Flask ğŸ¦ Â· Postman ğŸ±â€ğŸ Â·  Pythonanywhere

--------------------------------------------------------------------------------------------------------------------------------------------------

### Use case
The client @TheBridge_Tech wants to develop a social media monitoring to measure the impact of the brand during the lapse of a Bootcamp, in order to design commercial actions.


### I've perform the following tasks:

0. Training a classification model with a Corpus of Tweets in Spanish.

1. Collection of the tweets where the @TheBridge_Tech account is mentioned from the first day of the bootcamp (13 June) until the last day of class (5 October).

2. Storage in an SQL database in 2 normalized tables (tweets, users).

3. Business analysis.

4. To determine the sentiment of the tweets, NER, and find with NLP the most relevant hashtags, n-grams...

5. Deloyment of a Flask API with the model and the database to easily access the predictions for new tweets.

# Do you want to discover more? 

 - model training: https://github.com/irene-glez/tweets-analysis-NLP/blob/main/src/notebooks/0.model_training.ipynb
 - scraping and storage in database: https://github.com/irene-glez/tweets-analysis-NLP/blob/main/src/notebooks/1.scraping_%26_storage.ipynb
 - business analysis: https://github.com/irene-glez/tweets-analysis-NLP/blob/main/src/notebooks/2.business_analysis.ipynb
 - sentiment determination and NLP analysis: https://github.com/irene-glez/tweets-analysis-NLP/blob/main/src/notebooks/3.NLP_analysis.ipynb
 - API: https://github.com/irene-glez/tweets-analysis-NLP/blob/main/src/app.py


Many Thanks!
--------------------------------------------------------------------------------------------------------------------------------------------------

